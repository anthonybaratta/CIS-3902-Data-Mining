{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Segmentation Using Clustering Techniques and the Mall Data\n",
        "<p>This is a data analysis mini-project that will allow you to perform customer segmentation on a specific group of mall customers. You will identify the best possible cluster using the K-means unsupervised machine learning algorithm to find the univariate (described by a single quantitative variable) or bivariate (described by two quantitative variables that have a relationship with each otehr) clusters.  Once these clusters are identified, summary statistics can be performed on these to identify the best marketing group. You are then able to develop better marketing campaigns based on these groups!</p>\n",
        "<p>The data includes features Customer ID, Gender, Age, Annual Income in Thousands, and a Spending Score from 1 to 100 (1 is low, 100 is high based on a rating of spending patterns of the customer).</p>\n",
        "<p>Our goal is to determine segments of customers based on these features in order to perfect a marketing campaign tailored to each group of customer. In order to build the clusters for our marketing campaign using Python and a powerful library called sklearn which helps with developing our powerful models, we are going to apply the K-means algorithm to build our clusters first using one variable, then two!</p>\n",
        "<p>Here is a video that you can watch that describes the process if you want more information: <a href=\"https://www.youtube.com/watch?v=iwUli5gIcU0\">Python Customer Segmentation and Clustering</a></p>\n",
        "<p>Here is a video to watch if you want to review your understanding of the K-means algorithm: <a href=\"https://www.youtube.com/watch?v=4b5d3muPQmA\">Statquest K-means algorithm explained in 8 minutes</a>\n",
        "<p>To run the code in this notebook which is automatically opened in Google Colab, a powerful cloud environment for Python \"Jupyter\" Notebooks, simply review the \"Markdown\" or text cells for explanation of the code, then click on the small triangle to the right of code cells to run the code. You can even add your own code cells by clicking on the \"+Code\" menu item and experimenting with code or edit the code in a cell!</p>\n",
        "<p>To Save your notebook, from the menu select \"File . . . download . . . .ipynb\".</p>\n",
        "<p>To save your notebook as a PDF file, from the menu select \"File . . . Print\".</p>\n",
        "<p>Happy Learning!</p>"
      ],
      "metadata": {
        "id": "WV72JpMv_9hh"
      },
      "id": "WV72JpMv_9hh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Executing the Code\n",
        "<p>To run the code in this notebook which is opened in Google Colab, a powerful cloud environment for Python \"Jupyter\" Notebooks, simply read the \"Markdown\" or text cells for explanation of the code, then click on the small triangle to the right of code cells to run the code. You can even add your own code cells by clicking on the \"+Code\" menu item and experimenting with code!</p><p>\n",
        "\n",
        "To Save your notebook, from the menu select \"File . . . download . . . .ipynb\".</p><p>\n",
        "\n",
        "To save your notebook as a PDF file, from the menu select \"File . . . Print\".</p>\n",
        "\n",
        "Happy Learning!"
      ],
      "metadata": {
        "id": "Qbw-LxoBhfUJ"
      },
      "id": "Qbw-LxoBhfUJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Read the Input File"
      ],
      "metadata": {
        "id": "vBV9l4iAF5rD"
      },
      "id": "vBV9l4iAF5rD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import libaries for processing\n",
        "<p>Libraries add valuable code that can be called so we don't have to write everything from scratch! You can look at the green comments that start with \"#\" to learn the purpose of each library.</p>"
      ],
      "metadata": {
        "id": "Pgou52tIDmqZ"
      },
      "id": "Pgou52tIDmqZ"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "19e74984",
      "metadata": {
        "id": "19e74984"
      },
      "outputs": [],
      "source": [
        "# pandas lets us work with our data (reading, writing, maintaining)\n",
        "# we will name it \"pd\" and that is how we will reference pandas when we use it in our code\n",
        "import pandas as pd\n",
        "# seaborn is for creating pretty charts\n",
        "# we will name it \"sns\"\n",
        "import seaborn as sns\n",
        "# matplotlib.pyplot is also for pretty charts, we will call it \"plt\" in our code\n",
        "import matplotlib.pyplot as plt\n",
        "# sklearn is what we use for machine learning algorithms in our code, we are going to import KMeans\n",
        "# because that is the algorithm we want to use for our clustering\n",
        "# there are MANY algorithms available in sklearn!\n",
        "from sklearn.cluster import KMeans\n",
        "# the next two lines of code will just let us ignore pesky warnings which don't impact our output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read the input file \"Mall_Customers.csv\"\n",
        "<p> Notice how we are using pandas or \"pd\" to read a csv input file. Did you know you can save Excel worksheets as \"csv\" or comma separated values files?</p>\n",
        "<p> Our file is going to be stored in the variable \"df\" after we read it. Then we will refer to the dataframe or table the file is stored in as \"df\" when we want to use it in our analysis.</p>"
      ],
      "metadata": {
        "id": "2jKM4hDqEvK0"
      },
      "id": "2jKM4hDqEvK0"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "e5d4048e",
      "metadata": {
        "id": "e5d4048e"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('https://absentdata.com/wp-content/uploads/2023/03/Mall_Customers.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dac5228",
      "metadata": {
        "id": "5dac5228"
      },
      "outputs": [],
      "source": [
        "# Let's look at the first five records with the \"head\" command. You can look at the last five\n",
        "# records with df.tail()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83bddb6b",
      "metadata": {
        "id": "83bddb6b"
      },
      "source": [
        "# Univariate Analysis\n",
        "<p>Remember, Univariate Analysis means analyzing one variable with our cluster analysis using the K-means algorithm. We will first complete some exploratory analysis to learn more about our data through charts.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a04efad",
      "metadata": {
        "id": "9a04efad"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a74eddb1",
      "metadata": {
        "id": "a74eddb1"
      },
      "outputs": [],
      "source": [
        "# Let's use seaborn or \"sns\" to create a distribution plot with the \"Annual income (k$)\" feature from our data\n",
        "sns.distplot(df['Annual Income (k$)'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "b17fa7fc",
      "metadata": {
        "id": "b17fa7fc"
      },
      "outputs": [],
      "source": [
        "# Let's put the column names in a variable called \"columns\" - we will be using it soon!\n",
        "# You won't see any output from this cell, it just creates the variable in memory called \"columns\"\n",
        "columns=['Age', 'Annual Income (k$)','Spending Score (1-100)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1672df7a",
      "metadata": {
        "id": "1672df7a"
      },
      "outputs": [],
      "source": [
        "# here we are using that \"columns\" variable and the loop again\n",
        "# to see more than one Kernel Density Plot\n",
        "columns=['Age', 'Annual Income (k$)','Spending Score (1-100)']\n",
        "for i in columns:\n",
        "    plt.figure()\n",
        "    sns.kdeplot(df[i],shade=True);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1396ec6a",
      "metadata": {
        "id": "1396ec6a"
      },
      "outputs": [],
      "source": [
        "# Just for fun, here are some boxplots\n",
        "columns=['Age', 'Annual Income (k$)','Spending Score (1-100)']\n",
        "for i in columns:\n",
        "    plt.figure()\n",
        "    sns.boxplot(data=df,x='Gender',y=df[i]);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2732996",
      "metadata": {
        "id": "e2732996"
      },
      "outputs": [],
      "source": [
        "# Lets see the percent of records by Gender\n",
        "# Look's like we have a few more Female records (normalize=true makes this a percent rather than a simple count)\n",
        "df['Gender'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bde0c4c",
      "metadata": {
        "id": "0bde0c4c"
      },
      "source": [
        "# Bivariate Analysis\n",
        "<p>Now we are going to have some fun with two variables at a time!</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d257fb4",
      "metadata": {
        "id": "1d257fb4"
      },
      "outputs": [],
      "source": [
        "# Let's use seaborn (sns) for scatterplots.\n",
        "# Seaborn is so powerful!\n",
        "sns.scatterplot(data=df,x='Annual Income (k$)',y='Spending Score (1-100)', hue='Gender')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b579b18d",
      "metadata": {
        "id": "b579b18d"
      },
      "outputs": [],
      "source": [
        "# Now we will use seaborn (sns) to create pairplots for all of the data at once\n",
        "# First we are going to make remove the unique variable \"Customer ID\" from df\n",
        "# Then we will make our pairplots - it doesn't make sense to use the unique identifier\n",
        "df = df.drop(['CustomerID'], axis=1)\n",
        "sns.pairplot(df,hue='Gender')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13bc68fd",
      "metadata": {
        "id": "13bc68fd"
      },
      "outputs": [],
      "source": [
        "# Let's use the group by command\n",
        "# to create a summary table of the averages\n",
        "# by Gender\n",
        "df.groupby(['Gender'])['Age', 'Annual Income (k$)','Spending Score (1-100)'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7735be45",
      "metadata": {
        "id": "7735be45"
      },
      "outputs": [],
      "source": [
        "# How about a correlation matrix? We are learning\n",
        "# more and more about the data before we try to cluster\n",
        "# the data into groups for our marketing campaign\n",
        "df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec10b51f",
      "metadata": {
        "id": "ec10b51f"
      },
      "outputs": [],
      "source": [
        "# a heatmap gives us a different way to look at the correlations\n",
        "# it is more visual!\n",
        "sns.heatmap(df.corr(),annot=True,cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75187364",
      "metadata": {
        "id": "75187364"
      },
      "source": [
        "# Clustering - Univariate and Bivariate\n",
        "<p>We are now going to use the kmeans algorithm to cluster our customers from the data in \"df\". Our clusters will be built using one variable first (Univariate), then two variables (Bivariate). We won't do Multivariate (more than two variables) because that requires some work with the categorical \"Gender\" feature but the video that is linked above covers clustering with more than two variables.</p>\n",
        "<p>Want to review that kmeans algorithm? There is a video linked above from statsquest but do you want it explained \"like I'm five\"? Here you go - kmeans explained with a box of crayons!</p>\n",
        "<p>Alright, imagine you have a big box of crayons, but you're not quite sure how many different colors are in there. Now, let's say you want to organize them into groups based on their colors, but you're not sure how many groups there should be.</p><p>\n",
        "\n",
        "So, here's what you do with the K-means algorithm:<br><br>\n",
        "\n",
        "Pick Some Groups: First, you guess how many groups you want. Let's say you decide on three groups.<br><br>\n",
        "\n",
        "Find Centers: Next, you pick three crayons randomly from the box and decide that those will be the centers of your groups. These crayons are like the leaders of their own groups.<br><br>\n",
        "\n",
        "Sort Crayons: Now, you go through all the crayons in the box and put each one into the group of the crayon that it's closest to in color. So, if a crayon is more like the blue center crayon than the red or green center crayon, you put it in the blue group.<br><br>\n",
        "\n",
        "Move Centers: After you've sorted all the crayons, you look at each group and find the average color of all the crayons in that group. Then, you move the center of each group to be at that average color.\n",
        "\n",
        "Repeat: Now, you do steps 3 and 4 again and again until the centers of the groups stop moving much. This means the crayons have settled into their groups pretty well.<br><br>\n",
        "\n",
        "Done!: Once the centers stop moving much, you're done! You've organized your crayons into groups based on their colors, and you know how many groups there are.<br><br></p><p>\n",
        "\n",
        "So, K-means is like sorting crayons into color groups by guessing how many groups there should be, picking some starting crayons as leaders for each group, and then moving those leaders around until the groups make sense.</p>\n",
        "<p> Now on to our Python example!</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b4167759",
      "metadata": {
        "id": "b4167759"
      },
      "outputs": [],
      "source": [
        "# create our clustering \"object\" using the kmeans algorithm\n",
        "# remember, we imported the code behind this earlier with the sklearn library!\n",
        "clustering1=KMeans(n_clusters=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d46dcc",
      "metadata": {
        "id": "d1d46dcc"
      },
      "outputs": [],
      "source": [
        "# we decided on 3 clusters, kind of randomly, and we are going to use Annual Income to create the clusters\n",
        "clustering1.fit(df[['Annual Income (k$)']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43dbd7da",
      "metadata": {
        "id": "43dbd7da"
      },
      "outputs": [],
      "source": [
        "# this looks kind of weird, but it is the clustering assignment for\n",
        "# each record - 0, 1 or 2 which represent the three clusters\n",
        "# Python and lots of stuff in code often starts with 0\n",
        "# when it is numbering things\n",
        "clustering1.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89848a49",
      "metadata": {
        "id": "89848a49"
      },
      "outputs": [],
      "source": [
        "# We should create a new attribute called \"Income Cluster\"\n",
        "# in our dataframe df\n",
        "# this shows which cluster was assigned according to\n",
        "# our univariate clustering using Kmeans by that income variable\n",
        "# then we will just peek at the first five records again\n",
        "df['Income Cluster']=clustering1.labels_\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dab384f",
      "metadata": {
        "id": "6dab384f"
      },
      "outputs": [],
      "source": [
        "# Let's see the number of records from our file \"df\" in each cluster labeled 0, 1 or 2\n",
        "df['Income Cluster'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clustering Inertia\n",
        "<p> Here is a new term for you! Remember the box of crayons?</p>\n",
        "<p>Revisiting those crayons, remember you've organized them into different color groups using the K-means algorithm. Now, for each crayon in a group, you measure how far it is from the center of its group. Then, you add up all these distances for every crayon in every group.</p><p>\n",
        "\n",
        "The clustering inertia is essentially the sum of all these distances. If the crayons within each group are very close to their group's center, the clustering inertia will be low because the sum of these distances will be small. But if the crayons within each group are spread out and far from their group's center, the clustering inertia will be higher because the sum of these distances will be larger.</p><p>\n",
        "\n",
        "So, in simpler terms, clustering inertia measures how tightly packed the crayons are within their groups. A lower clustering inertia usually means better clustering because it suggests that the groups are more cohesive and well-separated.</p>"
      ],
      "metadata": {
        "id": "tEwrKoaGOh7i"
      },
      "id": "tEwrKoaGOh7i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc31b4e",
      "metadata": {
        "id": "9cc31b4e"
      },
      "outputs": [],
      "source": [
        "# the lower this number is, the more tightly packed the crayons are\n",
        "# of course, we need to think in terms of records and their income feature!\n",
        "clustering1.inertia_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inertia Scores for Different Numbers of Clusters - Which is Best?\n",
        "<p>For the next code cell, we are going to look through creating the clusters using K-means for 1 cluster, then two clusters, etc. all the way to 10 clusters. The variable inertia_scores will contain the inertia scores for clustering the data for each of those 1 to 10 clusters using the annual income data. These scores can be used to evaluate the optimal number of clusters for the dataset.</p><p> Typically, you would plot these scores and look for an \"elbow point\" where the inertia starts to decrease at a slower rate, which indicates a good number of clusters to use.</p>\n",
        "<p>We can also just look for the lowest inertia score! Which number of clusters is best?</p>\n",
        "<p>Notice how the third score is the closest to our previous inertia score for 3 clusters. Slight differences are caused by the way the algorithm works each time it is applied.</p>"
      ],
      "metadata": {
        "id": "JbAXnndBPXVa"
      },
      "id": "JbAXnndBPXVa"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "feHCvvYwRJ-C"
      },
      "id": "feHCvvYwRJ-C"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ff2ed562",
      "metadata": {
        "id": "ff2ed562"
      },
      "outputs": [],
      "source": [
        "inertia_scores=[]\n",
        "for i in range(1,11):\n",
        "    kmeans=KMeans(n_clusters=i)\n",
        "    kmeans.fit(df[['Annual Income (k$)']])\n",
        "    inertia_scores.append(kmeans.inertia_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86abc742",
      "metadata": {
        "id": "86abc742"
      },
      "outputs": [],
      "source": [
        "inertia_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a043861f",
      "metadata": {
        "id": "a043861f"
      },
      "outputs": [],
      "source": [
        "# this is the \"elbow\" plot\n",
        "# the best number of clusters is where the line\n",
        "# forms the elbow or quits dropping\n",
        "plt.plot(range(1,11),inertia_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd7ea3b",
      "metadata": {
        "id": "7bd7ea3b"
      },
      "outputs": [],
      "source": [
        "# Now for our marketing group, let's\n",
        "# see the characteristics of the customers that\n",
        "# were assigned to each cluster! We can then\n",
        "# build marketing campaigns around this new knowledge.\n",
        "# Just imagine if we had MORE data on our customers!\n",
        "df.groupby('Income Cluster')['Age', 'Annual Income (k$)',\n",
        "                              'Spending Score (1-100)'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1017d697",
      "metadata": {
        "id": "1017d697"
      },
      "source": [
        "# Bivariate Clustering\n",
        "<p>Let's explore the clustering using two variables! This is called Bivariate Clustering. Do you think we will be able to learn more about our customers with more than one variable? Will this help our marketing campaign?</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05f4f22",
      "metadata": {
        "id": "d05f4f22"
      },
      "outputs": [],
      "source": [
        "# We are going to use the K-means algorithm to create 5 clusters\n",
        "# using the annual income and the spending score\n",
        "# We will go ahead and build the clusters and assign the\n",
        "# clustering labels, then peek at the data frame!\n",
        "clustering2=KMeans(n_clusters=5)\n",
        "clustering2.fit(df[['Annual Income (k$)','Spending Score (1-100)']])\n",
        "df['Spending and Income Cluster']=clustering2.labels_\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0474806d",
      "metadata": {
        "id": "0474806d"
      },
      "outputs": [],
      "source": [
        "# Let's work with those inertia scores  . .\n",
        "# We built five clusters, is this the best number of clusters\n",
        "# based on the inertia scores?\n",
        "inertia_scores2=[]\n",
        "for i in range(1,11):\n",
        "    kmeans2=KMeans(n_clusters=i)\n",
        "    kmeans2.fit(df[['Annual Income (k$)','Spending Score (1-100)']])\n",
        "    inertia_scores2.append(kmeans2.inertia_)\n",
        "\n",
        "plt.plot(range(1,11),inertia_scores2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "2f1c656b",
      "metadata": {
        "id": "2f1c656b"
      },
      "outputs": [],
      "source": [
        "# let's plot the clusteres\n",
        "# We are going to create a variable with the centers\n",
        "# we will use that to highlight those points in our clustering chart\n",
        "centers=pd.DataFrame(clustering2.cluster_centers_)\n",
        "centers.columns=['x','y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab399b0",
      "metadata": {
        "id": "4ab399b0"
      },
      "outputs": [],
      "source": [
        "# Now let's create this cool clustering chart!\n",
        "# Question: How would you describe each cluster? Can you use this for more effective marketing?\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(x=centers['x'],y=centers['y'],s=100,c='black',marker=('*'))\n",
        "\n",
        "sns.scatterplot(data=df,x='Annual Income (k$)',y='Spending Score (1-100)',hue='Spending and Income Cluster',palette='tab10')\n",
        "plt.savefig('clustering_bivariate.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83a7f6c9",
      "metadata": {
        "id": "83a7f6c9"
      },
      "outputs": [],
      "source": [
        "# here is a table of the percentages of records in each cluster\n",
        "# Which cluster is the largest?\n",
        "pd.crosstab(df['Spending and Income Cluster'],df['Gender'],normalize='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a22958c7",
      "metadata": {
        "id": "a22958c7"
      },
      "outputs": [],
      "source": [
        "# Here is another table to help us explore and understand our customers.\n",
        "df.groupby('Spending and Income Cluster')['Age', 'Annual Income (k$)',\n",
        "                              'Spending Score (1-100)'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd7fe9da",
      "metadata": {
        "id": "dd7fe9da"
      },
      "source": [
        "# The End\n",
        "<p>Now you should have a better understanding of clustering with the K-means algorithm!</p><p>You as an analyst are getting ready to talk to the Marketing Director . . . what will you tell them about your cluster analysis?</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55269d8d",
      "metadata": {
        "id": "55269d8d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}